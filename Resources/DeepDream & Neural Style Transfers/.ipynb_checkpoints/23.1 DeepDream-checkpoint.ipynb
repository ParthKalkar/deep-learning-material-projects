{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing DeepDream in Keras\n",
    "\n",
    "We firstly load the InceptionV3 model which tends to produce some of the best visuals. Feel free to try VGG16, VGG19, Xception and ResNet50.\n",
    "\n",
    "Code obtained and edited from F. Chollet (Created of Keras)\n",
    "- \n",
    "https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/8.2-deep-dream.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import inception_v3, resnet50\n",
    "from keras import backend as K\n",
    "\n",
    "# This settings disables all training specific operations\n",
    "K.set_learning_phase(0)\n",
    "\n",
    "# Load InceptionV3\n",
    "model = inception_v3.InceptionV3(weights = 'imagenet', include_top = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We create a dictionary of coefficients quantifying, how much the layer’s activation contributes to the loss you’ll seek to maximize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_contributions = {\n",
    "    'mixed2': 0.7,\n",
    "    'mixed3': 2.2,\n",
    "    'mixed4': 1.2,\n",
    "    'mixed5': .2,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define our tensor that contains the maximized Loss (the weighted sum of the L2 norm of the activations of the layer desfined above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable += will be deprecated. Use variable.assign_add if you want assignment to the variable value or 'x = x + y' if you want a new python Tensor object.\n"
     ]
    }
   ],
   "source": [
    "# Map layer names to layer instances\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "\n",
    "# loss defined by adding layer contributions\n",
    "loss = K.variable(0.)\n",
    "\n",
    "for layer_name in layer_contributions:\n",
    "    coeff = layer_contributions[layer_name]\n",
    "    \n",
    "    # activation gets the layer output\n",
    "    activation = layer_dict[layer_name].output\n",
    "    scaling = K.prod(K.cast(K.shape(activation), 'float32'))\n",
    "\n",
    "    # we add the l2 norm\n",
    "    loss += coeff * K.sum(K.square(activation[:, 2: -2, 2: -2, :])) / scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Gradient-Ascent Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the image or 'dream' :) that is stored in this tensor \n",
    "dream = model.input\n",
    "\n",
    "# Obtains the gradients wrt to the loss\n",
    "grads = K.gradients(loss, dream)[0]\n",
    "\n",
    "# Normalizes the gradient \n",
    "grads /= K.maximum(K.mean(K.abs(grads)), 1e-7)\n",
    "\n",
    "# Creates a Keras function to get the value of the loss & gradients wrt to the input\n",
    "outputs = [loss, grads]\n",
    "fetch_loss_and_grads = K.function([dream], outputs)\n",
    "\n",
    "def eval_loss_and_grads(x):\n",
    "    \"\"\"returns the loss and gradient values\"\"\"\n",
    "    outs = fetch_loss_and_grads([x])\n",
    "    loss_value = outs[0]\n",
    "    grad_values = outs[1]\n",
    "    return loss_value, grad_values\n",
    "\n",
    "def gradient_ascent(x, iterations, step, max_loss=None):\n",
    "    \"\"\"Implements gradient access for a specified number of iterations\"\"\"\n",
    "    for i in range(iterations):\n",
    "        loss_value, grad_values = eval_loss_and_grads(x)\n",
    "        if max_loss is not None and loss_value > max_loss:\n",
    "            break\n",
    "        print('...Loss value at', i, ':', loss_value)\n",
    "        x += step * grad_values\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the Deep Dream Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image shape (353, 529)\n",
      "...Loss value at 0 : 1.0304297\n",
      "...Loss value at 1 : 1.2510272\n",
      "...Loss value at 2 : 1.6979636\n",
      "...Loss value at 3 : 2.271832\n",
      "...Loss value at 4 : 2.8770106\n",
      "...Loss value at 5 : 3.4737113\n",
      "...Loss value at 6 : 4.0769672\n",
      "...Loss value at 7 : 4.617928\n",
      "...Loss value at 8 : 5.15317\n",
      "...Loss value at 9 : 5.685014\n",
      "...Loss value at 10 : 6.1906824\n",
      "...Loss value at 11 : 6.645993\n",
      "...Loss value at 12 : 7.0928683\n",
      "...Loss value at 13 : 7.5481906\n",
      "...Loss value at 14 : 7.9534693\n",
      "...Loss value at 15 : 8.386046\n",
      "...Loss value at 16 : 8.765054\n",
      "...Loss value at 17 : 9.139767\n",
      "...Loss value at 18 : 9.5182705\n",
      "...Loss value at 19 : 9.86855\n",
      "Processing image shape (494, 740)\n",
      "...Loss value at 0 : 2.864695\n",
      "...Loss value at 1 : 4.0144286\n",
      "...Loss value at 2 : 4.9185443\n",
      "...Loss value at 3 : 5.688157\n",
      "...Loss value at 4 : 6.3830137\n",
      "...Loss value at 5 : 7.0187526\n",
      "...Loss value at 6 : 7.596686\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from keras.preprocessing import image\n",
    "import imageio\n",
    "\n",
    "def resize_img(img, size):\n",
    "    img = np.copy(img)\n",
    "    factors = (1,\n",
    "               float(size[0]) / img.shape[1],\n",
    "               float(size[1]) / img.shape[2], 1)\n",
    "    return scipy.ndimage.zoom(img, factors, order=1)\n",
    "\n",
    "def save_img(img, fname):\n",
    "    pil_img = deprocess_image(np.copy(img))\n",
    "    imageio.imwrite(fname, pil_img)\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    img = image.load_img(image_path)\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = inception_v3.preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "def deprocess_image(x):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.reshape((3, x.shape[2], x.shape[3]))\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    else:\n",
    "        x = x.reshape((x.shape[1], x.shape[2], 3))\n",
    "    x /= 2.\n",
    "    x += 0.5\n",
    "    x *= 255.\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "step = 0.01 #Step size for gradient ascent\n",
    "num_octave = 3 #number of octaves to be run\n",
    "octave_scale = 1.4 #this is the scale for each ensuing octive will be 1.4 times large than the previous\n",
    "iterations = 20 #number of gradient ascent operations we execute \n",
    "max_loss = 10.0 #our early stoping metric, if loss is > max_loss we break the gradient ascent loop\n",
    "\n",
    "base_image_path = './images/aurora_norway.jpg'\n",
    "\n",
    "# Load our image \n",
    "img = preprocess_image(base_image_path)\n",
    "\n",
    "# Initialize a list of tuples for our different images sizes/scales \n",
    "original_shape = img.shape[1:3]\n",
    "successive_shapes = [original_shape]\n",
    "for i in range(1, num_octave):\n",
    "    shape = tuple([int(dim / (octave_scale ** i)) for dim in original_shape])\n",
    "    successive_shapes.append(shape)\n",
    "\n",
    "# Reverse list of shapes, so that they are in increasing order\n",
    "successive_shapes = successive_shapes[::-1]\n",
    "\n",
    "# Resize the Numpy array of the image to our smallest scale\n",
    "original_img = np.copy(img)\n",
    "shrunk_original_img = resize_img(img, successive_shapes[0])\n",
    "\n",
    "for shape in successive_shapes:\n",
    "    print('Processing image shape', shape)\n",
    "    img = resize_img(img, shape)\n",
    "    img = gradient_ascent(img,\n",
    "                          iterations=iterations,\n",
    "                          step=step,\n",
    "                          max_loss=max_loss)\n",
    "\n",
    "    upscaled_shrunk_original_img = resize_img(shrunk_original_img, shape)\n",
    "    same_size_original = resize_img(original_img, shape)\n",
    "    lost_detail = same_size_original - upscaled_shrunk_original_img\n",
    "\n",
    "    img += lost_detail\n",
    "    shrunk_original_img = resize_img(original_img, shape)\n",
    "    save_img(img, fname='dream_at_scale_' + str(shape) + '.png')\n",
    "    \n",
    "save_img(img, fname='final_dream.png')\n",
    "print(\"DeepDreaming Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "image_path = 'final_dream.png'\n",
    "\n",
    "# Show our Final Dream Image \n",
    "img1 = image.load_img(image_path)\n",
    "plt.imshow(img1);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
